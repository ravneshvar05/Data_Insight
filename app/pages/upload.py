"""
Upload page for dataset upload and validation.
"""

import streamlit as st
import pandas as pd
from pathlib import Path
import tempfile
import sys

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.utils.config import get_config
from src.utils.validators import DataValidator
from src.utils.logger import get_logger

logger = get_logger(__name__)


def show():
    """Display the upload page."""
    st.header("üìÅ Upload Your Dataset")
    st.markdown("Upload a CSV file to begin the analysis.")
    
    # File uploader
    uploaded_file = st.file_uploader(
        "Choose a CSV file",
        type=['csv'],
        help="Maximum file size: 100MB"
    )
    
    if uploaded_file is not None:
        try:
            # Save to temporary file
            with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = Path(tmp_file.name)
            
            # Initialize validator
            config = get_config()
            validator = DataValidator(config.all)
            
            # Validate file
            is_valid, error_msg = validator.validate_file(tmp_path)
            
            if not is_valid:
                st.error(f"‚ùå File validation failed: {error_msg}")
                tmp_path.unlink()
                return
            
            # Load CSV
            with st.spinner("Loading CSV file..."):
                df = validator.load_csv(tmp_path)
            
            # Clean up temp file
            tmp_path.unlink()
            
            # Validate DataFrame
            is_valid, error_msg = validator.validate_dataframe(df)
            
            if not is_valid:
                st.error(f"‚ùå Dataset validation failed: {error_msg}")
                return
            
            # Success! Store in session state
            st.session_state.df = df
            st.session_state.dataset_name = uploaded_file.name
            st.session_state.profile_results = None  # Reset profiling
            st.session_state.visualizations = []  # Reset visualizations
            st.session_state.insights = None  # Reset insights
            
            st.success(f"‚úÖ Dataset loaded successfully!")
            
            # Display dataset preview
            st.subheader("Dataset Preview")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total Rows", f"{len(df):,}")
            with col2:
                st.metric("Total Columns", f"{len(df.columns):,}")
            with col3:
                st.metric("Memory Usage", f"{df.memory_usage(deep=True).sum() / (1024 * 1024):.2f} MB")
            
            st.markdown("### First 10 Rows")
            st.dataframe(df.head(10), use_container_width=True)
            
            st.markdown("### Column Information")
            col_info = pd.DataFrame({
                'Column': df.columns,
                'Type': df.dtypes.astype(str),
                'Non-Null Count': df.count().values,
                'Null Count': df.isnull().sum().values
            })
            st.dataframe(col_info, use_container_width=True)
            
            st.info("üëâ Navigate to **Data Profiling** to analyze your dataset.")
            
            logger.info(f"Dataset uploaded: {uploaded_file.name} ({len(df)} rows, {len(df.columns)} columns)")
        
        except Exception as e:
            st.error(f"‚ùå Error loading dataset: {str(e)}")
            logger.error(f"Error loading dataset: {str(e)}")
    
    else:
        # Show instructions when no file is uploaded
        st.info("üëÜ Upload a CSV file to get started")
        
        st.markdown("### Requirements")
        st.markdown("""
        - File format: CSV
        - Maximum size: 100 MB
        - Minimum rows: 2
        - Minimum columns: 1
        - Valid column names (non-empty strings)
        """)
        
        st.markdown("### What happens next?")
        st.markdown("""
        1. **Data Profiling**: Comprehensive statistical analysis
        2. **Visualizations**: AI-powered chart recommendations
        3. **Insights**: Business insights generated by LLMs
        4. **Report**: Downloadable PDF report
        """)
